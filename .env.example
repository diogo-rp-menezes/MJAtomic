# .env.example
# Example environment file. Copy to .env.local for local development.

# --- LLM & Embedding Configuration ---
LLM_PROVIDER=google
LLM_MODEL_SMART="gemini-2.5-pro"
LLM_MODEL_FAST="gemini-2.5-flash"

# Embedding provider can be 'google' or 'ollama'
EMBEDDING_PROVIDER="google" 
GOOGLE_EMBEDDING_MODEL="gemini-embedding-001"
OLLAMA_EMBEDDING_MODEL="qwen3-embedding:0.6b"
OLLAMA_BASE_URL="http://host.docker.internal:11434" # URL for Docker containers to reach Ollama on the host

REQUEST_DELAY_SECONDS=1 # Delay in seconds between API calls to avoid rate limits

# --- API Keys ---
GOOGLE_API_KEY=
GOOGLE_API_KEY_1=
GOOGLE_API_KEY_2=
# ... add more keys as needed

# --- Docker & Workspace Configuration ---
MJATOMIC_DOCKER_HOST_IP="localhost"
MJATOMIC_DOCKER_USER="dockeruser"
LOCAL_WORKSPACE_PATH="C:/Users/YourUser/dev/mjatomic_workspace" # Use absolute path
WORKSPACE_PATH="/app/workspace"

# --- Service Configuration ---
REDIS_HOST="redis"
POSTGRES_URL="postgresql://devagent:atomicpass@db:5432/devagent_db"
PGVECTOR_COLLECTION_NAME="mjatomic_codebase"

# --- General Agent Settings ---
LOG_LEVEL="INFO"
