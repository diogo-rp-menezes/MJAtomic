# Database
POSTGRES_USER=devagent
POSTGRES_PASSWORD=atomicpass
POSTGRES_DB=devagent_db
POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_URL=postgresql+psycopg://devagent:atomicpass@db:5432/devagent_db

# Redis
REDIS_HOST=redis
REDIS_PORT=6379

# Vector DB
PGVECTOR_COLLECTION_NAME=code_collection

# LLM Global (Default Provider)
# Options: google, ollama, local
LLM_PROVIDER=google

# Google Configuration
GOOGLE_API_KEY=your_google_api_key_here

# Local / Ollama Configuration
# Use the IP address of your host machine where Ollama/LM Studio is running
OLLAMA_BASE_URL=http://26.155.132.173:1234
OLLAMA_LLM_MODEL=gemini-2.5-flash

# Embeddings Configuration
# Options: google, ollama, local
EMBEDDING_PROVIDER=local
# If using hybrid setup (e.g. Ollama for embeddings), specify URL here
OLLAMA_EMBEDDING_URL=http://ollama:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Specific Agents Configuration (Optional Overrides)
# If not set, they generally follow LLM_PROVIDER
FULLSTACK_MODEL=gemini-2.5-flash
# FULLSTACK_BASE_URL= # Leave empty to use Google if LLM_PROVIDER is google. Set if you want Fullstack to use a specific Local URL.
TECH_LEAD_MODEL=gemini-2.5-flash

# Workspace
LOCAL_WORKSPACE_PATH=./workspace
